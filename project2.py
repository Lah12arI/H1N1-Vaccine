# -*- coding: utf-8 -*-
"""Project2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1A2XoVd2HUsgjORh03ovtT-EvrBpDgofR

Prediction of H1N1 Vaccination

import Libraries
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
!pip install category_encoders
from category_encoders import OrdinalEncoder
from sklearn.impute import SimpleImputer
from sklearn.ensemble import AdaBoostClassifier , GradientBoostingClassifier,RandomForestClassifier
from sklearn.ensemble import BaggingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.pipeline import make_pipeline

import numpy as np
import pandas as pd

import matplotlib.pyplot as plt

!pip install plotly_express
import plotly_express as px
import seaborn as sns

palette = sns.color_palette("rainbow", 8)

from sklearn.cluster import KMeans
from sklearn.neighbors import KNeighborsClassifier

from sklearn.model_selection import train_test_split

from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler

from sklearn.metrics import r2_score

import warnings
warnings.filterwarnings("ignore")

"""Load the data

"""

df = pd.read_csv("https://raw.githubusercontent.com/Premalatha-success/Datasets/main/h1n1_vaccine_prediction.csv")

df.sample(25)

###Problem statement-https://www.kaggle.com/competitions/prediction-of-h1n1-vaccination/data

df.shape

df.head()

df.dtypes

df.tail()

df.info()

df.isnull().sum()

df.describe()

sns.countplot(x="unique_id",data=df)

sns.countplot(x="marital_status",data=df)

sns.countplot(x="race",hue="sex",data=df)

sns.countplot(x="housing_status",hue="employment",data=df)

sns.countplot(x="no_of_children",hue="no_of_adults",data=df)

df.hist(figsize=(10,15))
plt.show()

sns.boxplot(x="h1n1_awareness",y="avoid_large_gatherings",data=df)

duplicate=df.duplicated()
print(duplicate.sum())

df.boxplot(column=["h1n1_awareness"])
def remove_outlier(col):
    sorted(col)
    Q1,Q3=col.quantile([0.25,0.75])
    IQR=Q3-Q1
    lower_range=Q1-1.5*IQR
    upper_range=Q3+1.5*IQR
    return lower_range,upper_range

low_h1n1_awareness,high_h1n1_awareness=remove_outlier(df["h1n1_awareness"])
df["h1n1_awareness"]=np.where(df["h1n1_awareness"]>high_h1n1_awareness,high_h1n1_awareness,df["h1n1_awareness"])
df["h1n1_awareness"]=np.where(df["h1n1_awareness"]<low_h1n1_awareness,low_h1n1_awareness,df["h1n1_awareness"])

df.boxplot(column=["h1n1_awareness"])

pd.crosstab(df['employment'],df['no_of_children'])

df.dropna(inplace=True)

df.isnull().sum()

sns.pairplot(df,diag_kind='kde')
plt.show()

corr=df.corr()
corr

target = 'h1n1_vaccine'
train,val= train_test_split(df,train_size=0.80, test_size=0.20, stratify=df[target], random_state=2)
test,val= train_test_split(df,train_size=0.80, test_size=0.20, stratify=df[target], random_state=2)

#Check Cardinality
train.describe(exclude='number')

"""Feature Engineering

"""

def engineer(df):

    # Create "behaviorals" feature
    behaviorals = [col for col in df.columns if 'behavioral' in col]
    df['behaviorals'] = df[behaviorals].sum(axis=1)

    # Transform employment_status feature values("Not in Labor Force" -> "Unemployed")
    fixed_data = []
    for i in df["employment"]:
      if i == "Not in Labor Force":
        fixed_data.append("Unemployed")
      else:
        fixed_data.append(i)
    df["employment"] = fixed_data

    # Remove any feature with cardinality of over 30
    selected_cols = df.select_dtypes(include=['number', 'object'])
    colnames = selected_cols.columns.tolist()
    labels = selected_cols.nunique()

    selected_features = labels[labels <= 30].index.tolist()
    df = df[selected_features]

    return df


train = engineer(train)
val = engineer(val)
test = engineer(test)

features = train.drop(columns=[target]).columns

# Diving training, validation, and testing data into X and y
X_train = train[features]
y_train = train[target]
X_val = val[features]
y_val = val[target]
X_test = test[features]
y_test=test[features]

"""Model"""



# ordinal encoding
pipe_ord = make_pipeline(
    OrdinalEncoder(),
    SimpleImputer(),
    RandomForestClassifier(n_estimators=100, random_state=10, max_depth=14)
)

pipe_ord.fit(X_train, y_train)
print(pipe_ord.score(X_val, y_val))

y_pred_test = pipe_ord.predict(X_test)
y_pred_test = pd.Series(y_pred_test)
y_pred_test.value_counts()

pipe_ord = make_pipeline(
    OrdinalEncoder(),
    SimpleImputer(),
    AdaBoostClassifier(n_estimators=100, random_state=10)
)

pipe_ord.fit(X_train, y_train)
print(pipe_ord.score(X_val, y_val))

y_pred_test = pipe_ord.predict(X_test)
y_pred_test = pd.Series(y_pred_test)
y_pred_test.value_counts()

pipe_ord = make_pipeline(
    OrdinalEncoder(),
    SimpleImputer(),
    BaggingClassifier(n_estimators=100, random_state=10)
)

pipe_ord.fit(X_train, y_train)
print(pipe_ord.score(X_val, y_val))

y_pred_test = pipe_ord.predict(X_test)
y_pred_test = pd.Series(y_pred_test)
y_pred_test.value_counts()

pipe_ord = make_pipeline(
    OrdinalEncoder(),
    SimpleImputer(),
    DecisionTreeClassifier()
)

pipe_ord.fit(X_train, y_train)
print(pipe_ord.score(X_val, y_val))

y_pred_test = pipe_ord.predict(X_test)
y_pred_test = pd.Series(y_pred_test)
y_pred_test.value_counts()

pipe_ord = make_pipeline(
    OrdinalEncoder(),
    SimpleImputer(),
    GradientBoostingClassifier(n_estimators=100,random_state=10)
)

pipe_ord.fit(X_train, y_train)
print(pipe_ord.score(X_val, y_val))

y_pred_test = pipe_ord.predict(X_test)
y_pred_test = pd.Series(y_pred_test)
y_pred_test.value_counts()

# Create the DataFrame including predictions with "id" feature from the original data as index
id = pd.Series(range(len(y_pred_test)))
y_pred_test = pd.Series(y_pred_test)
submission = pd.concat([id, y_pred_test], axis=1)
submission.rename(columns={0:"id", 1:target}, inplace=True)

# Display the submission data information
print(submission.shape)
print(submission.value_counts(target))



